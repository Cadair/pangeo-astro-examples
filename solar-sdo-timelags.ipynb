{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Dask to Compute AIA Timelags in Parallel\n",
    "## Will Barnes<sup>1</sup> and Stuart Mumford<sup>2</sup>\n",
    "### <sup>1</sup> Department of Physics and Astronomy, Rice University <sup>2</sup>University of Sheffield"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we'll show an example of how to use Dask to efficiently compute the timelag between two AIA channels from multi-wavelength AIA data. **The goal of this notebook is to show how Dask allows us to treat many individual FITS files as a single, out-of-core data cube.** By constructing a data cube from our stacks of FITS files for each EUV channel of AIA, we can scale the computation of the timelag in each pixel of the image across *many* computing cores. By structuring the data in this way, we are able to effectively leverage our computational resources against our large volume of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages\n",
    "\n",
    "First, we'll need to import a bunch of packages. Most importantly, we'll need the SunPy and Astropy libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: For this example, we need the bleeding-edge version of SunPy. This can be installed from GitHub. Once SunPy v1.0 is released, this will not be necessary.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! conda uninstall sunpy -y\n",
    "! git clone git@github.com:sunpy/sunpy.git ~/sunpy\n",
    "! cd ~/sunpy && python setup.py install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.ndimage.interpolation import shift\n",
    "import matplotlib.pyplot as plt\n",
    "import dask\n",
    "import dask.array as da\n",
    "import distributed\n",
    "from dask_kubernetes import KubeCluster\n",
    "import gcsfs\n",
    "from astropy.time import Time\n",
    "import astropy.io\n",
    "import astropy.units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.io.fits.hdu.base import BITPIX2DTYPE\n",
    "import sunpy\n",
    "from sunpy.map import Map\n",
    "from sunpy.instr.aia import aiaprep\n",
    "from sunpy.physics.differential_rotation import diffrot_map,solar_rotate_coordinate\n",
    "from sunpy.util.metadata import MetaDict\n",
    "import matplotlib.colors\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that we've got the most recent version. This should read `1.0.0.dev<commit-number>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sunpy.version.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be using a set of AIA data that has already been uploaded to Pangeo. This data consists of 6 hours of consecutive full-disk observations in the six EUV passbands of the AIA instrument: 94, 131, 171, 193, 211, and 335 Ã….\n",
    "\n",
    "Additionally, we've also created a \"prepped\" and \"derotated\" version of this dataset in which we've scaled all channels to a common resolution and removed the effect of differential rotation on the Sun such that, over time, the same pixel corresponds (approximately) to the same patch of Sun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcs = gcsfs.GCSFileSystem()\n",
    "sorted(gcs.ls('pangeo-data/SDO_AIA_Images/diffrot/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DIR = 'gcs://pangeo-data/SDO_AIA_Images/diffrot/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spin Up Cluster\n",
    "\n",
    "Now, let's create our Dask cluster. Because we are running on Pangeo, we can do this via the Dask Kubernetes module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dask_kubernetes import KubeCluster\n",
    "cluster = KubeCluster(n_workers=200)\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.dashboard_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = distributed.Client(cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cubes from FITS Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As noted previously, AIA data are stored in the FITS format, where the 4K-by-4K image at each timestep and wavelength is stored in an individual file. This means to form a timeseries for a given wavelength, we need to combine 6 hours worth of data. At a 12 s cadence, this works out to 1800 files per wavelength. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's define a data structure for stacking multiple FITS files to create an AIA data cube. This cube will be \"lazily\" evaluated such that the data will not be immediately loaded into memory. We'll call this object `AIACube`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_dtype_shape(head):\n",
    "    naxes = head['NAXIS']\n",
    "    dtype = BITPIX2DTYPE[head['BITPIX']]\n",
    "    shape = [head[f'NAXIS{n}'] for n in range(naxes, 0, -1)]\n",
    "    return dtype, shape\n",
    "\n",
    "\n",
    "def get_header(fn, hdu=0):\n",
    "    with fn as fi:\n",
    "        return MetaDict(sunpy.io.fits.get_header(fi)[hdu])\n",
    "\n",
    "\n",
    "class DelayedFITS:\n",
    "    def __init__(self, file, shape, dtype, hdu=0, verify=False):\n",
    "        self.shape = shape\n",
    "        self.dtype = dtype\n",
    "        self.file = file\n",
    "        self.hdu = hdu\n",
    "        self.verify = verify\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        with self.file as fi:\n",
    "            with astropy.io.fits.open(fi, memmap=True) as hdul:\n",
    "                if self.verify:\n",
    "                    hdul.verify('silentfix+warn')\n",
    "                return hdul[self.hdu].data[item]\n",
    "\n",
    "\n",
    "class AIACube(object):\n",
    "\n",
    "    def __init__(self, maps):\n",
    "        if not all([m.data.shape == maps[0].data.shape for m in maps]):\n",
    "            raise ValueError('All maps must have same dimensions')\n",
    "        if not all([m.data.dtype == maps[0].data.dtype for m in maps]):\n",
    "            raise ValueError('All maps must have same dtype')\n",
    "        self.maps = maps\n",
    "        self.time = self._get_time()\n",
    "\n",
    "    @classmethod\n",
    "    def from_files(cls, fits_files, **kwargs):\n",
    "        openfiles = dask.bytes.open_files(fits_files)\n",
    "        headers = cls._get_headers(openfiles, **kwargs)\n",
    "        dtype, shape = cls._get_dtype_and_shape(headers)\n",
    "        maps = cls._get_maps(openfiles, headers, dtype, shape, **kwargs)\n",
    "        return cls(maps)\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_maps(openfiles, headers, dtype, shape, **kwargs):\n",
    "        hdu = kwargs.get('hdu', 0)\n",
    "        verify = kwargs.get('verify', False)\n",
    "        arrays = [da.from_array(DelayedFITS(f, shape, dtype, hdu=hdu, verify=verify), chunks=shape)\n",
    "                  for f in openfiles]\n",
    "        return [Map(a, h) for a, h in zip(arrays, headers)]\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_headers(openfiles, **kwargs):\n",
    "        client = distributed.get_client()\n",
    "        futures = client.map(get_header, openfiles, hdu=kwargs.get('hdu', 0))\n",
    "        return client.gather(futures)\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_dtype_and_shape(headers):\n",
    "        dtypes = [validate_dtype_shape(h) for h in headers]\n",
    "        if not all([d == dtypes[0] for d in dtypes]):\n",
    "            raise ValueError('All maps must have same shape and dtype')\n",
    "        return dtypes[0]\n",
    "\n",
    "    def _get_time(self,):\n",
    "        return u.Quantity([(Time(m.meta['t_obs']) - Time(self.maps[0].meta['t_obs'])).to(u.s) \n",
    "                            for m in self.maps])\n",
    "\n",
    "    @property\n",
    "    def shape(self,):\n",
    "        return self.time.shape + self.maps[0].data.shape\n",
    "\n",
    "    @property\n",
    "    def dtype(self,):\n",
    "        return self.maps[0].data.dtype\n",
    "\n",
    "    @property\n",
    "    def unstacked_data(self,):\n",
    "        return [m.data for m in self.maps]\n",
    "\n",
    "    @property\n",
    "    def stacked_data(self,):\n",
    "        return da.stack(self.unstacked_data)\n",
    "\n",
    "    def rechunk(self, shape):\n",
    "        return self.stacked_data.rechunk(shape)\n",
    "\n",
    "    def average(self, **kwargs):\n",
    "        chunks = kwargs.get('chunks', (self.shape[0], self.shape[1]//10, self.shape[2]//10))\n",
    "        cube = self.rechunk(chunks)\n",
    "        return sunpy.map.Map(cube.mean(axis=0, dtype=np.float64), self.maps[0].meta.copy())\n",
    "\n",
    "    def submap(self, *args, **kwargs):\n",
    "        return AIACube([m.submap(*args, **kwargs) for m in self.maps])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a data cube for the 171 Ã… channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube = AIACube.from_files(os.path.join(SAVE_DIR, '171/*.fits' ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we've only read in the metadata and not the actual data. This is the *lazy* part of structure. The data is only read in when needed. However, we can still treat it much like a \"dense\" data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube.shape # time, space, space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at one of the maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "cube.maps[0].plot(vmin=1e2,vmax=1e4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also identify the active region (AR) we are interested in. Note that we can crop each map in the same place as we have already removed the effect of the rotation of the Sun. We will crop the image later on after we have computed the timelag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = cube.maps[0]\n",
    "blc = SkyCoord(-600*u.arcsec,-700*u.arcsec,frame=m.coordinate_frame)\n",
    "trc = SkyCoord(-100*u.arcsec,-200*u.arcsec,frame=m.coordinate_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,12))\n",
    "ax = fig.gca(projection=m)\n",
    "m.plot(axes=ax,title=False,vmin=1e2,vmax=1e4)\n",
    "m.draw_rectangle(blc,(trc.Tx - blc.Tx), (trc.Ty - blc.Ty), color='C0', lw=3)\n",
    "ax.grid(alpha=0)\n",
    "m.draw_grid(axes=ax,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also take a time average over the whole cube."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube_average = cube.average(chunks=cube.shape[:1]+(100,100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, the average is only computed when we need it. Until then, the data is represented as a Dask array, though we do have access to all of the necessary metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "cube_average.plot(title=False,vmin=1e2,vmax=1e4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube.maps[0].meta['exptime']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's create a cube for each wavelength."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = [94,131,171,193,211,335]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cubes = [AIACube.from_files(os.path.join(SAVE_DIR, f'{c:03d}/*.fits' ))\n",
    "         for c in channels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we need to normalize each channel to the exposure time. This is typically part of the \"prepping\" process. We can do this simply by dividing each map in each cube by the exposure time as found in the map metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cubes = [AIACube([Map(m.data/m.meta['exptime'], m.meta) for m in c.maps]) for c in cubes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timelags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do some science, we want to calculate the timelag in each pixel of our map. The **timelag**, or the delay which maximizes the cross-correlation between two timeseries, is a useful quantity for understanding the thermal evolution of the coronal plasma between the passbands of the AIA instrument.\n",
    "\n",
    "In temperature space, the EUV passbands on AIA have the following structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://iopscience.iop.org/0004-637X/753/1/35/downloadFigure/figure/apj431449f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the so-called \"temperature response functions\" and they show approximately what temperatures each channel or passband is sensitive too.\n",
    "\n",
    "As a blob of coronal plasma cools from 10 MK down to below 1 MK, we expect to see the intensity peak in consecutively cooler channels. If we then compute the cross-correlate of the intensity timeseries in two different channels as a function of the temporal offset between those two timeseries, the offset which maximizes the cross-correlation is the **timelag**. The timelag can then be used as a proxy for the plasma cooling time between two passbands. This method was first applied to AIA data by [Viall and Klimchuk (2012)](http://iopscience.iop.org/article/10.1088/0004-637X/753/1/35/meta). They computed the timelag in every pixel of AR NOAA 11082 as observed by AIA. In doing so, they revealed large-scale cooing patterns across the entire active region. An example of several cross-correlation curves in a single pixel is shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://iopscience.iop.org/0004-637X/753/1/35/downloadFigure/figure/apj431449f4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mathematically, we can express the timelag in terms of a Fourier transform, making it very simple to compute with Dask. We can express the cross-correlation $\\mathcal{C}$ between two channels $A$ and $B$ as,\n",
    "\n",
    "$$\n",
    "    \\mathcal{C}_{AB}(\\tau) = \\mathcal{I}_A(t)\\star\\mathcal{I}_B(t) = \\mathcal{I}_A(-t)\\ast\\mathcal{I}_B(t)\n",
    "$$\n",
    "\n",
    "where $\\star$ and $\\ast$ represent the correlation and convolution operators, respectively, $\\tau$ is the lag and\n",
    "\n",
    "$$\n",
    "    \\mathcal{I}_c(t)=\\frac{I_c(t)-\\bar{I}_c}{\\sigma_{c}},\n",
    "$$\n",
    "\n",
    "is the mean-subtracted and scaled intensity of channel $c$ as a function of time. Taking the fourier transform of both sides of the first equation and using the convolution theorem,\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\mathcal{F}\\{\\mathcal{C}_{AB}(\\tau)\\} &= \\mathcal{F}\\{\\mathcal{I}_A(-t)\\ast\\mathcal{I}_B(t)\\},\\\\\n",
    "    &= \\mathcal{F}\\{\\mathcal{I}_A(-t)\\}\\mathcal{F}\\{\\mathcal{I}_B(t)\\}.\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Taking the inverse Fourier transform, $\\mathcal{F}^{-1}$, of both sides of the above expression gives,\n",
    "\n",
    "$$\n",
    "    \\mathcal{C}_{AB}(\\tau) = \\mathcal{F}^{-1}\\{\\mathcal{F}\\{\\mathcal{I}_A(-t)\\}\\mathcal{F}\\{\\mathcal{I}_B(t)\\}\\}.\n",
    "$$\n",
    "\n",
    "Scaling $\\mathcal{C}_{AB}$ by the length of the intensity timeseries $I(t)$ yields the same result as that of the correlation defined in section 2 of [Viall and Klimchuk (2012)](http://iopscience.iop.org/article/10.1088/0004-637X/753/1/35/meta). Furthermore, the **timelag** between channels $A$ and $B$ is defined as,\n",
    "$$\n",
    "    \\tau_{AB} = \\mathrm{argmax}_{\\tau}\\,\\mathcal{C}_{AB}(\\tau).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fortunately for us, all of these operations are already implemented in `dask.array`! Since we have already shaped our data into a data cube, we just need to build the graph appropriately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll create a data structure to hold cubes for all EUV wavelengths and can compute the timelag in each pixel of our observation and return the resulting timelag to a single `Map` object for each pair of AIA EUV channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AIATimelags(object):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        if not all([a.shape[1:] == args[0].shape[1:] for a in args]):\n",
    "            raise ValueError('All spatial dimensions must be the same')\n",
    "        if not all([a.shape[0] == args[0].shape[0] for a in args]):\n",
    "            warnings.warn('Time dimensions are not all equal length')\n",
    "        self._cubes = {a.maps[0].meta['wavelnth']: a for a in args}\n",
    "        self.channels = sorted(list(self._cubes.keys()), key=lambda x: x)\n",
    "\n",
    "    def __getitem__(self, channel):\n",
    "        # Index\n",
    "        if type(channel) is int and channel not in self.channels:\n",
    "            channel = self.channels[channel]\n",
    "        # Convert from string\n",
    "        if type(channel) is str:\n",
    "            channel = float(channel)\n",
    "        return self._cubes[channel]\n",
    "    \n",
    "    @property\n",
    "    def needs_interpolation(self,):\n",
    "        if not all([c.shape[0] == self[0].shape[0] for c in self]):\n",
    "            return True\n",
    "        return ~np.all([u.allclose(c.time, self[0].time) for c in self])\n",
    "\n",
    "    @property\n",
    "    def timelags(self):\n",
    "        time = self._interpolate_time if self.needs_interpolation else self[0].time\n",
    "        delta_t = np.diff(time.value).cumsum()\n",
    "        return np.hstack([-delta_t[::-1], np.array([0]), delta_t]) * time.unit\n",
    "    \n",
    "    @property\n",
    "    def _interpolate_time(self,):\n",
    "        min_t = min([c.time.min() for c in self])\n",
    "        max_t = max([c.time.max() for c in self])\n",
    "        n_t = max([c.time.shape[0] for c in self])\n",
    "        return np.linspace(min_t, max_t, n_t)\n",
    "    \n",
    "    def _interpolate(self, time, cube):\n",
    "        t_interp = self._interpolate_time\n",
    "        def interp_wrapper(y):\n",
    "            return interp1d(time, y, axis=0, kind='linear', fill_value='extrapolate')(t_interp)\n",
    "        return da.map_blocks(interp_wrapper, cube, chunks=t_interp.shape+cube.chunks[1:],\n",
    "                             dtype=cube.dtype)\n",
    "\n",
    "    def correlation_2d(self, channel_a, channel_b, **kwargs):\n",
    "        # Shape must be the same in spatial direction\n",
    "        chunks = kwargs.get('chunks', (self[channel_a].shape[1]//10,\n",
    "                                       self[channel_a].shape[2]//10))\n",
    "        cube_a = self[channel_a].rechunk(self[channel_a].shape[:1]+chunks)\n",
    "        cube_b = self[channel_b].rechunk(self[channel_b].shape[:1]+chunks)\n",
    "        if self.needs_interpolation:\n",
    "            cube_a = self._interpolate(self[channel_a].time, cube_a)\n",
    "            cube_b = self._interpolate(self[channel_b].time, cube_b)\n",
    "        # Reverse the first timeseries\n",
    "        cube_a = cube_a[::-1, :, :]\n",
    "        # Normalize by mean and standard deviation\n",
    "        std_a = cube_a.std(axis=0)\n",
    "        std_a = da.where(std_a == 0, 1, std_a)\n",
    "        v_a = (cube_a - cube_a.mean(axis=0)[np.newaxis, :, :]) / std_a[np.newaxis, :, :]\n",
    "        std_b = cube_b.std(axis=0)\n",
    "        std_b = da.where(std_b == 0, 1, std_b)\n",
    "        v_b = (cube_b - cube_b.mean(axis=0)[np.newaxis, :, :]) / std_b[np.newaxis, :, :]\n",
    "        # FFT of both channels\n",
    "        fft_a = da.fft.rfft(v_a, axis=0, n=self.timelags.shape[0])\n",
    "        fft_b = da.fft.rfft(v_b, axis=0, n=self.timelags.shape[0])\n",
    "        # Inverse of product of FFTS to get cross-correlation (by convolution theorem)\n",
    "        cc = da.fft.irfft(fft_a * fft_b, axis=0, n=self.timelags.shape[0])\n",
    "        # Normalize by the length of the timeseries\n",
    "        return cc / cube_a.shape[0]\n",
    "\n",
    "    def make_correlation_map(self, channel_a, channel_b, **kwargs):\n",
    "        cc = self.correlation_2d(channel_a, channel_b, **kwargs)\n",
    "        bounds = kwargs.get('timelag_bounds', None)\n",
    "        if bounds is not None:\n",
    "            indices, = np.where(np.logical_and(self.timelags >= bounds[0],\n",
    "                                               self.timelags <= bounds[1]))\n",
    "            start = indices[0]\n",
    "            stop = indices[-1] + 1\n",
    "        else:\n",
    "            start = 0\n",
    "            stop = self.timelags.shape[0] + 1\n",
    "        max_cc = cc[start:stop, :, :].max(axis=0).compute()\n",
    "        meta = self[channel_a].maps[0].meta.copy()\n",
    "        del meta['instrume']\n",
    "        del meta['t_obs']\n",
    "        del meta['wavelnth']\n",
    "        meta['bunit'] = ''\n",
    "        meta['comment'] = f'{channel_a}-{channel_b} cross-correlation'\n",
    "        plot_settings = {'cmap': 'plasma'}\n",
    "        plot_settings.update(kwargs.get('plot_settings', {}))\n",
    "        correlation_map = sunpy.map.GenericMap(max_cc, meta, plot_settings=plot_settings)\n",
    "\n",
    "        return correlation_map\n",
    "\n",
    "    def make_timelag_map(self, channel_a, channel_b, **kwargs):\n",
    "        cc = self.correlation_2d(channel_a, channel_b, **kwargs)\n",
    "        bounds = kwargs.get('timelag_bounds', None)\n",
    "        if bounds is not None:\n",
    "            indices, = np.where(np.logical_and(self.timelags >= bounds[0],\n",
    "                                               self.timelags <= bounds[1]))\n",
    "            start = indices[0]\n",
    "            stop = indices[-1] + 1\n",
    "        else:\n",
    "            start = 0\n",
    "            stop = self.timelags.shape[0] + 1\n",
    "        i_max_cc = cc[start:stop, :, :].argmax(axis=0).compute()\n",
    "        max_timelag = self.timelags[start:stop][i_max_cc]\n",
    "        meta = self[channel_a].maps[0].meta.copy()\n",
    "        del meta['instrume']\n",
    "        del meta['t_obs']\n",
    "        del meta['wavelnth']\n",
    "        meta['bunit'] = 's'\n",
    "        meta['comment'] = f'{channel_a}-{channel_b} timelag'\n",
    "        plot_settings = {'cmap': 'RdBu_r', 'vmin': self.timelags[start:stop].value.min(),\n",
    "                         'vmax': self.timelags[start:stop].value.max()}\n",
    "        plot_settings.update(kwargs.get('plot_settings', {}))\n",
    "        timelag_map = sunpy.map.GenericMap(max_timelag, meta.copy(),\n",
    "                                           plot_settings=plot_settings.copy())\n",
    "        return timelag_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's create our timelag object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timelags = AIATimelags(*cubes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute and Visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's compute a timelag in every pixel of the AR! Because the computation in each pixel is independent, we can distribute the spatial dimensions across multiple cores.\n",
    "\n",
    "Let's first compute the timelag map for the 335-171 Ã… channel pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl_335_171 = timelags.make_timelag_map(335,171,timelag_bounds=(-3*u.hour,3*u.hour), chunks=(cube.shape[1]//25,cube.shape[2]//25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, we can plot our map in the usual way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,10))\n",
    "ax = fig.gca(projection=tl_335_171)\n",
    "im = tl_335_171.plot(axes=ax,vmin=-1e4,vmax=1e4,cmap='RdBu_r',title=False)\n",
    "ax.grid(alpha=0)\n",
    "fig.colorbar(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also compute the maximum value of the cross-correlation in each pixel to understand how correlated the two timeseries were."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_335_171 = timelags.make_correlation_map(335,171,timelag_bounds=(-3*u.hour,3*u.hour))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, we can plot our map in the usual way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,10))\n",
    "ax = fig.gca(projection=cc_335_171)\n",
    "im = cc_335_171.plot(axes=ax,vmin=0,vmax=1,cmap='magma',title=False)\n",
    "ax.grid(alpha=0)\n",
    "fig.colorbar(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aside: Functions for Computing Level 1.5 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_map = Map(os.path.join(SAVE_DIR,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_observer = ref_map.observer_coordinate\n",
    "reference_date = ref_map.date\n",
    "reference_center = ref_map.center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def derotate(aia_map):\n",
    "    new_coord = solar_rotate_coordinate(\n",
    "        aia_map.center,\n",
    "        reference_date,\n",
    "        new_observer_location=reference_observer,\n",
    "        rot_type='snodgrass')\n",
    "    xs_pixel = (new_coord.Tx - reference_center.Tx)/aia_map.scale.axis1\n",
    "    ys_pixel = (new_coord.Ty - reference_center.Ty)/aia_map.scale.axis2\n",
    "    shifted_data = shift(aia_map.data, [ys_pixel.value, xs_pixel.value])\n",
    "    derotated_map = Map(shifted_data, aia_map.meta)\n",
    "    return derotated_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def save_fits(aia_map):\n",
    "    fn = os.path.join(SAVE_DIR, 'lev1.5', '{detector}_lev1.5_{date}_{channel}.fits'.format(\n",
    "            detector=aia_map.meta['detector'].lower(), \n",
    "            date=aia_map.date.strftime('%Y%m%dT%H%M%S'),\n",
    "            channel=aia_map.meta['wavelnth']))\n",
    "    aia_map.save(fn)\n",
    "    return fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_level15_graph(cube):\n",
    "    m_prep = [dask.delayed(aiaprep)(m) for m in cube.maps]\n",
    "    m_derot = [derotate(m) for m in m_prep]\n",
    "    return [save_fits(m) for m in m_derot]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:conda]",
   "language": "python",
   "name": "conda-env-conda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
